import fs from "fs/promises";
import path from "path";
import cron from "node-cron";
import sources from "./config/rssSources.js";
import { scrapeRSS } from "./scrapers/rssScraper.js";
import http from "http";

const ALL_NEWS_FILE = path.resolve("./data/all_news.json");
const LAST_DATES_FILE = path.resolve("./data/last_dates.json");

async function ensureFiles() {
  await fs.mkdir("./data", { recursive: true });

  try { 
    await fs.access(ALL_NEWS_FILE); 
  } catch { 
    await fs.writeFile(ALL_NEWS_FILE, "[]"); 
  }

  try { 
    await fs.access(LAST_DATES_FILE); 
  } catch { 
    await fs.writeFile(LAST_DATES_FILE, "{}"); 
  }
}

async function loadJSON(file, fallback) {
  try {
    return JSON.parse(await fs.readFile(file, "utf8"));
  } catch {
    return fallback;
  }
}


async function saveJSON(file, data) {
  await fs.writeFile(file, JSON.stringify(data, null, 2), "utf8");
}

async function fetchAll() {
  await ensureFiles();

  let allNews = await loadJSON(ALL_NEWS_FILE, []);
  let lastDates = await loadJSON(LAST_DATES_FILE, {});

  console.log("\n====================================================");
  console.log(`ðŸŸ¦ Fetch cycle started: ${new Date().toISOString()}`);
  console.log("====================================================");

  let totalNew = 0;

  await Promise.allSettled(
    sources.map(async (source) => {
      console.log(`\nðŸŒ Fetching from: ${source.name}`);

      const items = await scrapeRSS(source);

      console.log(`ðŸ“¥ Extracted: ${items.length} items from ${source.name}`);

      const lastSourceDate = lastDates[source.name] || "1970-01-01T00:00:00Z";
      let added = 0;

      for (const item of items) {
        if (!item.date) continue;

        const itemDate = new Date(item.date).getTime();
        const lastDate = new Date(lastSourceDate).getTime();

        if (itemDate > lastDate) {
          allNews.push(item);
          added++;
          totalNew++;

          if (
            !lastDates[source.name] ||
            item.date > lastDates[source.name]
          ) {
            lastDates[source.name] = item.date;
          }
        }
      }

      console.log(`   âœ” New items added from ${source.name}: ${added}`);
    })
  );

  await saveJSON(ALL_NEWS_FILE, allNews);
  await saveJSON(LAST_DATES_FILE, lastDates);

  console.log("\n====================================================");
  console.log(`ðŸ’¾ Saved all news!`);
  console.log(`ðŸ“Š Total items stored in all_news.json: ${allNews.length}`);
  console.log(`ðŸŸ© New items added this cycle: ${totalNew}`);
  console.log("====================================================\n");
}

fetchAll();

cron.schedule("*/3 * * * *", fetchAll);
console.log("ðŸ•’ RSS Fetcher scheduled every 3 minutes...");


const PORT = process.env.PORT || 3000;

http.createServer((req, res) => {
  if (req.url === "/data") {
    fs.readFile(ALL_NEWS_FILE, "utf8").then(data => {
      res.writeHead(200, { "Content-Type": "application/json" });
      res.end(data);
    });
  } else {
    res.writeHead(200, { "Content-Type": "text/plain" });
    res.end("âœ… RSS Worker is running...\n");
  }
}).listen(PORT, () => {
  console.log(`âœ… Dummy server running on port ${PORT}`);
});
